# DAY 06 – На что похожа ерунда?
## Обработка текстовых данных 2
В рамках этого дня вы освоите более продвинутые способы работы с текстовыми данными.

## Оглавление

1. [Глава I](#глава-i) \
    1.1. [Преамбула](#преамбула)
2. [Глава II](#глава-ii) \
    2.1. [Общая инструкция](#общая-инструкция)
3. [Глава III](#глава-iii) \
    3.1. [Цели](#цели)
4. [Глава IV](#глава-iv) \
    4.1. [Задание](#задание)
5. [Глава V](#глава-v) \
    5.1. [Сдача работы и проверка](#сдача-работы-и-проверка)

## Глава I
### Преамбула

Вчера вы познакомились с простыми способами векторизации текстов, которые основаны на анализе статистики попадания конкретного слова в текст. Такие способы зачастую дают неплохой результат, но у них есть один значительный недостаток: они не учитывают контекст, в котором слово находится внутри текста. Под контекстом мы будем понимать те несколько слов, которые окружают рассматриваемое слово внутри текста. Сегодня вы изучите более сложную модель векторизации текстов - word2vec - которая преобразует тексты в числовые векторы фиксированной длины, учитывая контекст слов в них.

Также вы изучите еще один классификатор, основанный на уже известных вам решающих деревьях. Это градиентный бустинг над решающими деревьями. Его особенность заключается в том, что это не просто ансамбль деревьев, как случайный лес, но еще и модель, которая сама предсказывает свои ошибки и сразу пытается их корректировать.


## Глава II
### Общая инструкция

Методология Школы 21 может быть не похожа на тот образовательный опыт, который с вами случался ранее. Ее отличает высокий уровень автономии: у вас есть задача, вы должны ее выполнить. По большей части вам нужно будет самим добывать знания для ее решения. Второй важный момент – это peer-to-peer обучение. В образовательном процессе нет преподавателей и экспертов, перед которыми вы защищаете свой результат. Вы это делаете перед таким же учащимися, как и вы сами. У них есть чек-лист, который поможет им выполнить приемку вашей работы качественно.

Роль Школы 21 заключается в том, чтобы обеспечить через последовательность заданий и оптимальный уровень поддержки такую траекторию обучения, при которой вы освоите не только hard skills, но и научитесь самообучаться.

* Не доверяйте слухам и предположениям о том, как должно быть оформлено ваше решение. Этот документ является единственным источником, к которому стоит обращаться по большинству вопросов.
* Ваше решение будет оцениваться другими учащимися бассейна.
* Подлежат оцениванию только те файлы, которые вы выложили в GIT.
* В вашей папке не должно быть лишних файлов – только те, что были указаны в задании.
* Есть вопрос? Спросите коллегу справа. Не помогло? Спросите коллегу слева.
* Не забывайте, что у вас есть доступ к интернету и поисковым системам.
* Обсуждение заданий можно вести и в Slack бассейна.
* Будьте внимательные к примерам, указанным в этом документе – они могут иметь важные детали, которые не были оговорены другим способом.
* И да пребудет с вами Сила!



## Глава III
### Цели

Наша цель - научиться использовать word2vec, научиться работать с градиентным бустингом, а также расширить арсенал используемых библиотек для машинного обучения.


## Глава IV
### Задание

Сегодня вы продолжите работать с набором данных текстов из твитов. Вся работа у нас идет в Jupyter Notebooks / Google Colab. Ноутбук этого дня вы сможете найти здесь: `src/d06_task.ipynb`.


Что нужно сделать:
1. Проведите предобработку текстов. Создайте несколько моделей word2vec с параметрами, указанными в блокноте. Обучите их на всём пространстве текстов. Найдите по 15 синонимов и антонимов для 5 случайных слов из каждой из подвыборок позитивных и негативных твитов. Опишите, как влияет размер результирующего пространства и параметр минимальной встречаемости слов в выборке на нахождение синонимов. Постройте графики распределения слов в двумерном пространстве с помощью метода t-SNE и опишите, как влияют параметры модели на расположение точек на графике. Предскажите продолжение твита обученной с параметрами по умолчанию моделью w2v. Сравните результаты, полученные после обучения моделей с разным количеством эпох обучения.
2. Проведите классификацию текстов с помощью векторизатора doc2vec и градиентного бустинга над решающими деревьями. Подберите гиперпараметры моделей: минимальную встречаемость слова в текстах doc2vec, максимальную глубину деревьев бустинга, количество деревьев в бустинге.



## Глава V
### Сдача работы и проверка

1. Вам нужно загрузить в GIT в папку `src` свой Jupyter Notebook.
    1. Он должен содержать в себе весь требуемый код.
    2. Он должен называться `d06_desc.ipynb`.

